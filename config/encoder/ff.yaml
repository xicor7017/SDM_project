arch: mae
lr: 1e-4
batch_size: 4
training_iterations: 100000
logdir: pretrained_encoders/
run_name: temp
mask_ratio: 0.50